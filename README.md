# ğŸ¤ Voice Recognition System â€” CNN-RNN + NLP

[![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)](https://tensorflow.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/voice-recognition-cnn-rnn-nlp/blob/main/notebooks/Voice_Recognition_CNN_RNN_NLP.ipynb)

> A complete voice command recognition system using **CNN-RNN hybrid deep learning** with **NLP post-processing**. No external audio files needed â€” everything is auto-generated!

---

## âœ¨ Features

- ğŸµ **Auto-Generated Dataset** â€” 800 synthetic voice samples (no downloads!)
- ğŸ§  **CNN-RNN Hybrid Model** â€” Conv2D + Bidirectional LSTM
- ğŸ“ **NLP Post-Processing** â€” Action mapping, context tracking, response generation
- ğŸ“Š **Complete Visualizations** â€” Waveforms, spectrograms, confusion matrix
- ğŸ® **10 Voice Commands** â€” yes, no, up, down, left, right, stop, go, hello, help

---

## ğŸš€ Quick Start

### Option 1: Google Colab (Easiest)
Click the "Open in Colab" badge above!

### Option 2: Local Setup
```bash
git clone https://github.com/YOUR_USERNAME/voice-recognition-cnn-rnn-nlp.git
cd voice-recognition-cnn-rnn-nlp
pip install -r requirements.txt
python main.py
```

---

## ğŸ—ï¸ Architecture

```
Audio (.wav) â†’ MFCC Features â†’ CNN (Conv2DÃ—3) â†’ BiLSTM (Ã—2) â†’ Dense â†’ NLP
```

### Model Details

| Layer | Type | Details |
|-------|------|---------|
| 1-3 | Conv2D | 32â†’64â†’128 filters, BatchNorm, MaxPool, Dropout |
| 4-5 | BiLSTM | 128â†’64 units, dropout=0.3 |
| 6-7 | Dense | 128â†’64 units, BatchNorm, Dropout |
| 8 | Output | Softmax (10 classes) |

### NLP Post-Processing

| Feature | Description |
|---------|-------------|
| Confidence Filter | Rejects predictions below 40% |
| Action Mapping | `up` â†’ `MOVE_UP` (direction category) |
| Context Tracking | Detects navigation sequences |
| Response Generation | Natural language feedback |

---

## ğŸ“Š Dataset

| Command | Samples | Total |
|---------|---------|-------|
| yes, no, up, down, left, right, stop, go, hello, help | 80 each | **800** |

- Format: WAV, 16kHz, 1 second
- Auto-generated with unique spectral signatures per command

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py                    # Run complete pipeline
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Voice_Recognition_CNN_RNN_NLP.ipynb  # Jupyter notebook
â”œâ”€â”€ src/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/                    # Saved models (auto-generated)
â”œâ”€â”€ data/                      # Dataset (auto-generated)
â””â”€â”€ outputs/                   # Plots (auto-generated)
```

---

## ğŸ“ˆ Results

- Training Accuracy: ~95%+
- Test Accuracy: ~85-95%
- 10 voice commands classified with NLP-enhanced output

---

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **TensorFlow/Keras** â€” Deep learning model
- **Librosa** â€” Audio processing & MFCC extraction
- **NLTK** â€” Natural language processing
- **Scikit-learn** â€” Evaluation metrics
- **Matplotlib/Seaborn** â€” Visualizations

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE)

---

â­ **Star this repo if you find it useful!**
